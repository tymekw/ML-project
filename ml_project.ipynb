{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import urllib3  # self explanatory\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "confusion_matrix = [[0]*91 for i in range(90)]\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1\") # WORKS dope\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1\") # ALSO works dope but waaaay slower\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\") # WORKS FAAST"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def predict(my_image, width=None, height=None):\n",
    "    # commented for open_image_from_google\n",
    "    # my_image = image.smart_resize(my_image, size=(1024, 1024))\n",
    "    x = image.img_to_array(my_image)\n",
    "    if width is not None and height is not None:\n",
    "        x = tf.image.resize(x, [width, height], preserve_aspect_ratio=True)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = detector(x)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def open_image_from_google(coco):\n",
    "\n",
    "    # impath = \"D:\\\\AGH\\\\VI semestr\\\\ML\\\\datasetGoogle\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\test\\\\Apple\\\\964b69442edeec04.jpg\"\n",
    "    impath = \"D:\\\\AGH\\\\VI semestr\\\\ML\\\\datasetGoogle\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\test\\\\Apple\\\\964b69442edeec04.jpg\"\n",
    "\n",
    "    apple = Image.open(impath)\n",
    "    result, x = predict(apple)\n",
    "    results = {key:value.numpy() for key,value in result.items()}\n",
    "    detection_classes = results['detection_classes']\n",
    "    print(\"model thinks: \" + coco[detection_classes[0][0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_coco_labels():\n",
    "    http = urllib3.PoolManager()\n",
    "    r = http.request('GET', 'https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-paper.txt')\n",
    "    dane = r.data.decode('UTF-8')\n",
    "    my_data = dane.split('\\n')\n",
    "\n",
    "    coco = {i+1: my_data[i] for i in range(0,len(my_data))}\n",
    "    coco.pop(91)\n",
    "    return coco\n",
    "\n",
    "\n",
    "\n",
    "def get_downloadable_labels_str(coco):\n",
    "    d = {value:1 for value in coco.values()}\n",
    "    # tmp = d[\"street sign\"]\n",
    "\n",
    "    # nowa googlowa          stara coco\n",
    "    d[\"traffic sign\"] = d.pop(\"street sign\")\n",
    "    d[\"bull\"] = d.pop(\"cow\")\n",
    "    d[\"glasses\"] = d.pop(\"eye glasses\")\n",
    "    d[\"boot\"] = d.pop(\"shoe\")\n",
    "    d[\"hair dryer\"] = d.pop(\"hair drier\")\n",
    "    d[\"doughnut\"] = d.pop(\"donut\")\n",
    "    d[\"microwave oven\"] = d.pop(\"microwave\")\n",
    "    d[\"telephone\"] = d.pop(\"cell phone\")\n",
    "    d[\"computer keyboard\"] = d.pop(\"keyboard\")\n",
    "    d[\"remote control\"] = d.pop(\"remote\")\n",
    "    d[\"computer mouse\"] = d.pop(\"mouse\")\n",
    "    d[\"television\"] = d.pop(\"tv\")\n",
    "    d[\"Kitchen dining room table\"] = d.pop(\"dining table\")\n",
    "    d[\"plant\"] = d.pop(\"potted plant\")\n",
    "    d[\"ski\"] = d.pop(\"skis\")\n",
    "    d[\"volleyball\"] = d.pop(\"sports ball\")\n",
    "    d[\"coffee cup\"] = d.pop(\"cup\")\n",
    "    d[\"flying disc\"] = d.pop(\"frisbee\")\n",
    "    # hairbrush\n",
    "    # d.pop(\"hair brush\")\n",
    "\n",
    "    labels = list(d.keys())\n",
    "    lb = [x.capitalize() for x in labels]\n",
    "    lb1 = [label.replace(\" \",\"_\") for label in lb]\n",
    "    str1 = \" \"\n",
    "    names = str1.join(lb1)\n",
    "    print(names)\n",
    "    return names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_paths_to_photos_and_labels(dataset_path=\"E:\\\\ML_DATASET\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\train\"):\n",
    "\n",
    "    directory_contents = os.listdir(dataset_path)\n",
    "\n",
    "    class_path_dict = {}\n",
    "\n",
    "    for subdirectory in directory_contents:\n",
    "        images = os.listdir(dataset_path + \"\\\\\" + subdirectory)\n",
    "\n",
    "        for image_ in images:\n",
    "            if image_.endswith(\".jpg\"):\n",
    "                full_image_path = dataset_path + \"\\\\\" + subdirectory + \"\\\\\" + image_\n",
    "                if subdirectory.lower() in class_path_dict:\n",
    "                    class_path_dict[subdirectory.lower()].append(full_image_path)\n",
    "                else:\n",
    "                    class_path_dict[subdirectory.lower()] = [full_image_path]\n",
    "\n",
    "    return class_path_dict\n",
    "\n",
    "\n",
    "def get_all_images_metadata_dict(path=\"E:\\\\ML_DATASET\\\\OIDv4_ToolKit\\\\OID\\\\csv_folder\\\\train-annotations-bbox.csv\"):\n",
    "    my_dict = {}\n",
    "\n",
    "    correct_class_id = class_id_to_coco_label_map.keys()\n",
    "\n",
    "    with open(path, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            if row[0] not in my_dict:\n",
    "                if row[2] in correct_class_id:\n",
    "                    my_dict[row[0]] = []\n",
    "                    my_dict[row[0]].append(row[1:])\n",
    "            else:\n",
    "                if row[2] in correct_class_id:\n",
    "                    my_dict[row[0]].append(row[1:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return my_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_class_id_to_open_image_label_map(path = \"E:\\\\ML_DATASET\\\\OIDv4_ToolKit\\\\OID\\\\csv_folder\\\\class-descriptions-boxable.csv\"):\n",
    "    f = open(path)\n",
    "    class_map = {}\n",
    "    for line in f:\n",
    "        data_line = line.rstrip().split(',')\n",
    "        class_map[data_line[0]] = data_line[1]\n",
    "    return class_map\n",
    "\n",
    "\n",
    "def convert_open_image_label_to_coco(class_map):\n",
    "\n",
    "    class_map = {value.lower():key for key, value in class_map.items()}\n",
    "\n",
    "    class_map[\"street sign\"] = class_map.pop(\"traffic sign\")\n",
    "    class_map[\"cow\"] = class_map.pop(\"bull\")\n",
    "    class_map[\"eye glasses\"] = class_map.pop(\"glasses\")\n",
    "    class_map[\"shoe\"] = class_map.pop(\"boot\")\n",
    "    class_map[\"hair drier\"] = class_map.pop(\"hair dryer\")\n",
    "    class_map[\"donut\"] = class_map.pop(\"doughnut\")\n",
    "    class_map[\"microwave\"] = class_map.pop(\"microwave oven\")\n",
    "    class_map[\"cell phone\"] = class_map.pop(\"telephone\")\n",
    "    class_map[\"keyboard\"] = class_map.pop(\"computer keyboard\")\n",
    "    class_map[\"remote\"] = class_map.pop(\"remote control\")\n",
    "    class_map[\"mouse\"] = class_map.pop(\"computer mouse\")\n",
    "    class_map[\"tv\"] = class_map.pop(\"television\")\n",
    "    class_map[\"dining table\"] = class_map.pop(\"kitchen dining room table\")\n",
    "    class_map[\"potted plant\"] = class_map.pop(\"plant\")\n",
    "    class_map[\"skis\"] = class_map.pop(\"ski\")\n",
    "    class_map[\"sports ball\"] = class_map.pop(\"volleyball\")\n",
    "    class_map[\"cup\"] = class_map.pop(\"coffee cup\")\n",
    "    class_map[\"frisbee\"] = class_map.pop(\"flying disc\")\n",
    "    # hairbrush\n",
    "\n",
    "    return {value:key for key, value in class_map.items()}\n",
    "\n",
    "\n",
    "def remove_non_coco_labels(class_id_to_coco_label_map):\n",
    "    coco_list  = list(coco.values())\n",
    "    class_id_to_only_coco_map = {}\n",
    "    for key,val in class_id_to_coco_label_map.items():\n",
    "        if val in coco_list:\n",
    "            class_id_to_only_coco_map[key] = val\n",
    "\n",
    "    return class_id_to_only_coco_map\n",
    "\n",
    "\n",
    "\n",
    "def get_image_labels_with_bbox(metadata):\n",
    "    labes_bboxes = []\n",
    "    for entry in metadata:\n",
    "        bbox = [float(i) for i in entry[3:7]]\n",
    "        labes_bboxes.append([class_id_to_coco_label_map[entry[1]],bbox])\n",
    "\n",
    "    return labes_bboxes\n",
    "\n",
    "\n",
    "def predict_single_image(path=\"D:\\\\AGH\\\\VI semestr\\\\ML\\\\datasetGoogle\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\test\\\\Baseball glove\\\\0298c70279b6e842.jpg\", width=None, height=None):\n",
    "    image_name = os.path.basename(path).split(\".\")[0]\n",
    "    image_ = Image.open(path)\n",
    "    result = predict(image_,width,height)\n",
    "    results = {key:value.numpy() for key,value in result.items()}\n",
    "    return results, image_name\n",
    "\n",
    "\n",
    "def compute_iou(groundtruth_box, detection_box):\n",
    "    g_xmin, g_xmax, g_ymin, g_ymax = groundtruth_box\n",
    "    d_ymin, d_xmin, d_ymax, d_xmax = detection_box\n",
    "\n",
    "    xa = max(g_xmin, d_xmin)\n",
    "    ya = max(g_ymin, d_ymin)\n",
    "    xb = min(g_xmax, d_xmax)\n",
    "    yb = min(g_ymax, d_ymax)\n",
    "\n",
    "    intersection = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
    "\n",
    "    boxAArea = (g_xmax - g_xmin + 1) * (g_ymax - g_ymin + 1)\n",
    "    boxBArea = (d_xmax - d_xmin + 1) * (d_ymax - d_ymin + 1)\n",
    "\n",
    "    return intersection / float(boxAArea + boxBArea - intersection)\n",
    "\n",
    "\n",
    "def update_confusion_matrix(oryginal_label_bbox, detected_label_bbox):\n",
    "    if detected_label_bbox == None:\n",
    "        confusion_matrix[coco_readable_to_index[oryginal_label_bbox[0]]-1][-1] += 1\n",
    "    else:\n",
    "        confusion_matrix[coco_readable_to_index[oryginal_label_bbox[0]]-1][coco_readable_to_index[detected_label_bbox[0]]-1] += 1\n",
    "\n",
    "\n",
    "\n",
    "def perform_analysis(model_result, image_name):\n",
    "    image_metadata_list = all_images_metadata_dict[image_name]\n",
    "    labels_bboxes_original = get_image_labels_with_bbox(image_metadata_list)\n",
    "\n",
    "\n",
    "    detected_classes = model_result['detection_classes'][0]\n",
    "    detected_classes_accuracy = model_result['detection_scores'][0]\n",
    "    detected_classes_bboxes = model_result['detection_boxes'][0]\n",
    "\n",
    "    labels_bboxes_detected = []\n",
    "    for d_class, score, bbox in zip(detected_classes,detected_classes_accuracy, detected_classes_bboxes):\n",
    "        if score >= 0.5:\n",
    "            labels_bboxes_detected.append([coco[d_class], list(bbox)])\n",
    "\n",
    "\n",
    "    for bbox_oryginal in labels_bboxes_original:\n",
    "        tmp = []\n",
    "        best_detected_bbox = None\n",
    "        for bbox_detected in labels_bboxes_detected:\n",
    "            iou = compute_iou(bbox_oryginal[1], bbox_detected[1])\n",
    "            if iou >= 0.5:\n",
    "                tmp.append([iou,bbox_detected])\n",
    "        if len(tmp) > 0:\n",
    "            tmp.sort(key = lambda x: x[0])\n",
    "            best_detected_bbox = tmp[-1][1]\n",
    "\n",
    "        update_confusion_matrix(bbox_oryginal, best_detected_bbox)\n",
    "\n",
    "\n",
    "def run_for_given_directory(dir_name):\n",
    "    global confusion_matrix;\n",
    "    confusion_matrix = [[0]*91 for i in range(90)]\n",
    "    dataset_path = \"E:\\\\ML_DATASET\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\train\"\n",
    "    subdirectory = dir_name\n",
    "\n",
    "    images = os.listdir(dataset_path + \"\\\\\" + subdirectory)\n",
    "    val_err = 0\n",
    "\n",
    "    print(\"subdirectory: \" + subdirectory)\n",
    "    for image_ in images:\n",
    "        if image_.endswith(\".jpg\"):\n",
    "            print(\"processing image: \" + str(image_))\n",
    "            full_image_path = dataset_path + \"\\\\\" + subdirectory + \"\\\\\" + image_\n",
    "            try:\n",
    "                results, image_name = predict_single_image(full_image_path)\n",
    "            except ValueError:\n",
    "                print(\"Val error for picture: \", image_)\n",
    "                val_err += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "            try:\n",
    "                perform_analysis(results, image_name)\n",
    "            except KeyError:\n",
    "                print(\"Key error for picture: \", image_)\n",
    "                continue\n",
    "\n",
    "def draw_bar_chart(values, labels, title, filename):\n",
    "    _values, _labels = zip(*sorted(zip(values, labels)))\n",
    "    positions = np.arange(len(_values)) + 0.5\n",
    "    plt.figure(num=None, figsize=(24, 17))\n",
    "    plt.barh(positions, _values, align='center')\n",
    "    plt.yticks(positions, _labels)\n",
    "    plt.tick_params(axis='y', labelsize=8)\n",
    "    plt.xlabel('')\n",
    "    plt.title(title)\n",
    "    ax = plt.axes()\n",
    "    ax.xaxis.grid(True)\n",
    "    plt.savefig(filename, papertype='a2')\n",
    "\n",
    "\n",
    "def get_all_detections(class_name):\n",
    "    return confusion_matrix[coco_readable_to_index[class_name]-1][:-1]\n",
    "\n",
    "def get_TP(class_name):\n",
    "    return confusion_matrix[coco_readable_to_index[class_name]-1][coco_readable_to_index[class_name]-1]\n",
    "\n",
    "# not detected\n",
    "def get_FN(class_name):\n",
    "    return confusion_matrix[coco_readable_to_index[class_name]-1][-1]\n",
    "\n",
    "def get_FP(class_name):\n",
    "    return sum(get_all_detections(class_name)) - get_TP(class_name)\n",
    "\n",
    "\n",
    "\n",
    "def get_precision(class_name):\n",
    "    return get_TP(class_name) / get_all_detections(class_name)\n",
    "\n",
    "def get_recall(class_name):\n",
    "    return get_TP(class_name) / ((get_TP(class_name))+get_FN(class_name))\n",
    "\n",
    "def get_F1_score(class_name):\n",
    "    numerator = 2 * get_TP(class_name)\n",
    "    denominator = numerator + get_FP(class_name) + get_FN(class_name)\n",
    "\n",
    "    return numerator/denominator\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "coco = get_coco_labels()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person Bicycle Car Motorcycle Airplane Bus Train Truck Boat Traffic_light Fire_hydrant Stop_sign Parking_meter Bench Bird Cat Dog Horse Sheep Elephant Bear Zebra Giraffe Hat Backpack Umbrella Handbag Tie Suitcase Snowboard Kite Baseball_bat Baseball_glove Skateboard Surfboard Tennis_racket Bottle Plate Wine_glass Fork Knife Spoon Bowl Banana Apple Sandwich Orange Broccoli Carrot Hot_dog Pizza Cake Chair Couch Bed Mirror Window Desk Toilet Door Laptop Oven Toaster Sink Refrigerator Blender Book Clock Vase Scissors Teddy_bear Toothbrush Traffic_sign Bull Glasses Boot Hair_dryer Doughnut Microwave_oven Telephone Computer_keyboard Remote_control Computer_mouse Television Kitchen_dining_room_table Plant Ski Volleyball Coffee_cup Flying_disc\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Person Bicycle Car Motorcycle Airplane Bus Train Truck Boat Traffic_light Fire_hydrant Stop_sign Parking_meter Bench Bird Cat Dog Horse Sheep Elephant Bear Zebra Giraffe Hat Backpack Umbrella Handbag Tie Suitcase Snowboard Kite Baseball_bat Baseball_glove Skateboard Surfboard Tennis_racket Bottle Plate Wine_glass Fork Knife Spoon Bowl Banana Apple Sandwich Orange Broccoli Carrot Hot_dog Pizza Cake Chair Couch Bed Mirror Window Desk Toilet Door Laptop Oven Toaster Sink Refrigerator Blender Book Clock Vase Scissors Teddy_bear Toothbrush Traffic_sign Bull Glasses Boot Hair_dryer Doughnut Microwave_oven Telephone Computer_keyboard Remote_control Computer_mouse Television Kitchen_dining_room_table Plant Ski Volleyball Coffee_cup Flying_disc'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco = get_coco_labels()\n",
    "\n",
    "coco_readable_to_index = {value:key for key, value in coco.items()}\n",
    "get_downloadable_labels_str(coco)\n",
    "# copy returned string\n",
    "# open in terminal\n",
    "# python main.py downloader --classes <paste_here_your_string> --type_csv <validation/test/train> --limit XX"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# obtain all needed dicts\n",
    "\n",
    "class_id_to_open_image_label_map = get_class_id_to_open_image_label_map()\n",
    "class_id_to_coco_label_map =  convert_open_image_label_to_coco(class_id_to_open_image_label_map)\n",
    "class_id_to_coco_label_map = remove_non_coco_labels(class_id_to_coco_label_map)\n",
    "\n",
    "all_images_metadata_dict = get_all_images_metadata_dict()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirectory: Traffic sign\n",
      "processing image: 00b933fe3dba90f7.jpg\n",
      "processing image: 00d5d782664b9752.jpg\n",
      "processing image: 077e92e17e2bd993.jpg\n",
      "processing image: 0948e2e8151c76a5.jpg\n",
      "processing image: 09ce71a8abd7d029.jpg\n",
      "processing image: 0a7e16f1759ee33d.jpg\n",
      "processing image: 12f3cbca6624663e.jpg\n",
      "processing image: 174659d5dd37e83d.jpg\n",
      "processing image: 189de62779313e6f.jpg\n",
      "processing image: 18bd91ebd6492881.jpg\n",
      "processing image: 1a42a4a463f58134.jpg\n",
      "processing image: 1de7f8815df79878.jpg\n",
      "processing image: 26294ca8077566ba.jpg\n",
      "processing image: 2631fc0f7ebe2372.jpg\n",
      "processing image: 29ac89fc18093432.jpg\n",
      "processing image: 2abb2008206cbefa.jpg\n",
      "processing image: 2b9a10ecd7f65e6f.jpg\n",
      "processing image: 2bb1a9789d444f5e.jpg\n",
      "processing image: 2bf77275b5819e0b.jpg\n",
      "processing image: 2da6a46122c628a9.jpg\n",
      "processing image: 2e30b1a5509af4f8.jpg\n",
      "processing image: 3b190c7b65512842.jpg\n",
      "processing image: 43ce44499403e5e7.jpg\n",
      "processing image: 47050d98937fa674.jpg\n",
      "processing image: 4711c4f59ab6a98d.jpg\n",
      "processing image: 47fe49542e761863.jpg\n",
      "processing image: 489be62ff802648b.jpg\n",
      "processing image: 4912efd68c180318.jpg\n",
      "processing image: 49244cf8287cfd2b.jpg\n",
      "processing image: 492a47f497ec5d7d.jpg\n",
      "processing image: 4b17333db81685a9.jpg\n",
      "processing image: 4dc7019d67cc80c4.jpg\n",
      "processing image: 4e7f1f47877068f8.jpg\n",
      "processing image: 4f840c36f6426091.jpg\n",
      "processing image: 502a0597ae66ebc3.jpg\n",
      "processing image: 5ad729c5a79534de.jpg\n",
      "processing image: 64277f05aa5cfa68.jpg\n",
      "processing image: 65b021a1b80a3650.jpg\n",
      "processing image: 6761f374d16e6bbd.jpg\n",
      "processing image: 67bdca7613fa9d70.jpg\n",
      "processing image: 6b495057e509ee86.jpg\n",
      "processing image: 6b6422260cf1ec54.jpg\n",
      "processing image: 6bed64df9251ea85.jpg\n",
      "processing image: 723978aea90984e9.jpg\n",
      "processing image: 73e8bc67b493287f.jpg\n",
      "processing image: 797632953bb49d5d.jpg\n",
      "processing image: 79f4fdf91ab44345.jpg\n",
      "processing image: 7cf90f0ba2445edb.jpg\n",
      "processing image: 82531961a98025d8.jpg\n",
      "processing image: 8319ea3cdd17ee75.jpg\n",
      "Val error for picture:  8319ea3cdd17ee75.jpg\n",
      "processing image: 83ee738c7df3d520.jpg\n",
      "processing image: 8df0c12140a140e5.jpg\n",
      "processing image: 8f3b6a77052fedf5.jpg\n",
      "processing image: 8f86d2e80e3905d4.jpg\n",
      "processing image: 93d493e1845f9352.jpg\n",
      "processing image: 9472d06281395aa8.jpg\n",
      "processing image: 947e82b276bbafaf.jpg\n",
      "processing image: 9651a7228ea0d893.jpg\n",
      "processing image: 9941811a3b162448.jpg\n",
      "processing image: 9a01bd124c18744e.jpg\n",
      "processing image: 9d07338d4531761f.jpg\n",
      "processing image: 9d09e56cf104fe3b.jpg\n",
      "processing image: 9fe37f55b858c2cd.jpg\n",
      "processing image: a296fde70f797229.jpg\n",
      "processing image: a2e6026ad50408f6.jpg\n",
      "processing image: a8fbba05778fa497.jpg\n",
      "processing image: a97703508766a7df.jpg\n",
      "processing image: ace563550c9b4bb5.jpg\n",
      "processing image: ae0af19ad648f26e.jpg\n",
      "processing image: aff563f408211631.jpg\n",
      "processing image: b224f9383e184947.jpg\n",
      "processing image: b3d682e715d904e7.jpg\n",
      "processing image: b7daaa1ebfb28ab4.jpg\n",
      "processing image: b7df5fab67046aac.jpg\n",
      "processing image: bd50a4b319e1fd51.jpg\n",
      "processing image: bd853c875445d96c.jpg\n",
      "processing image: be92fe244b5b438a.jpg\n",
      "processing image: c1350e9e16d99a84.jpg\n",
      "processing image: d05f335167e5611c.jpg\n",
      "processing image: d1575b870343a594.jpg\n",
      "processing image: d1b583bb72524472.jpg\n",
      "processing image: d6d68248bb970593.jpg\n",
      "processing image: d714e21747e131c7.jpg\n",
      "processing image: d7c50554f9dd472d.jpg\n",
      "processing image: dcadd29eb3117b42.jpg\n",
      "processing image: dd5b1e750297bd12.jpg\n",
      "processing image: e40cffb57f488dab.jpg\n",
      "processing image: e66f15cd0ca11867.jpg\n",
      "processing image: e67245e896fa4f88.jpg\n",
      "processing image: e96510dbc362f0b8.jpg\n",
      "processing image: eb8bdc8dbe872732.jpg\n",
      "processing image: ebd7ce6266a5372c.jpg\n",
      "processing image: ec12f9374ef7bb69.jpg\n",
      "processing image: f4579804671770a3.jpg\n",
      "processing image: f7ccde47441d021c.jpg\n",
      "processing image: f7fb716eed49881d.jpg\n",
      "processing image: f99852df77febb5b.jpg\n",
      "processing image: f9b5827c69793d64.jpg\n",
      "processing image: fdaf4e2740ad0650.jpg\n",
      "processing image: ff100c98eede18c6.jpg\n"
     ]
    }
   ],
   "source": [
    "run_for_given_directory(\"Traffic sign\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def draw_graphs(model_name, width, height):\n",
    "    draw_normalized_TP_graph(model_name, width, height)\n",
    "\n",
    "\n",
    "def draw_normalized_TP_graph(model_name, width, height):\n",
    "    tmp = []\n",
    "    for row in confusion_matrix:\n",
    "        normalized_row = []\n",
    "        for value in row:\n",
    "            normalized_row.append(value/(sum(row)))\n",
    "        tmp.append(normalized_row)\n",
    "\n",
    "    diag = [ tmp[i][i] for i in range(len(tmp)) ]\n",
    "    diag = diag[:-1]\n",
    "    coco_labels = list(get_coco_labels().values())\n",
    "    title = \"Normalized TP\"\n",
    "    filename = str(model_name) + '_' + str(width) + 'x' + str(height) + \"_Normalized_TP.pdf\"\n",
    "    draw_bar_chart(diag,coco_labels,title,filename)\n",
    "\n",
    "def draw_f1_score_graph(model_name, width, height):\n",
    "    coco_labels = list(coco.values())\n",
    "    f1_scores = []\n",
    "    for val in coco_labels:\n",
    "        f1_scores.append(get_F1_score(val))\n",
    "\n",
    "    title = \"F1 Scores\"\n",
    "    filename = str(model_name) + '_' + str(width) + 'x' + str(height) + \"_F1_scores.pdf\"\n",
    "    draw_bar_chart(f1_scores,coco_labels,title,filename)\n",
    "\n",
    "\n",
    "\n",
    "# rows equal to coco label id -1\n",
    "# same with columns\n",
    "# rows -> original classes\n",
    "# columns -> detected classes\n",
    "# last column indicates not found\n",
    "\n",
    "def test_all_dataset(model_name, width=None, height=None):\n",
    "    val_err = 0\n",
    "\n",
    "\n",
    "    dataset_path = \"E:\\\\ML_DATASET\\\\OIDv4_ToolKit\\\\OID\\\\Dataset\\\\train\"\n",
    "    directory_contents = os.listdir(dataset_path)\n",
    "    for subdirectory in directory_contents:\n",
    "        images = os.listdir(dataset_path + \"\\\\\" + subdirectory)\n",
    "        print(\"subdirectory: \" + subdirectory)\n",
    "        for image_ in images:\n",
    "            if image_.endswith(\".jpg\"):\n",
    "                print(\"processing image: \" + str(image_))\n",
    "                full_image_path = dataset_path + \"\\\\\" + subdirectory + \"\\\\\" + image_\n",
    "                try:\n",
    "                    results, image_name = predict_single_image(full_image_path, width, height)\n",
    "                except ValueError:\n",
    "                    val_err += 1\n",
    "                    continue\n",
    "\n",
    "                perform_analysis(results, image_name)\n",
    "\n",
    "    draw_graphs(model_name, width, height)\n",
    "\n",
    "# print(val_err)\n",
    "\n",
    "\n",
    "# print(confusion_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_confusion_matrix(model_name, width=None, height=None):\n",
    "    mat = np.matrix(confusion_matrix)\n",
    "    name = str(width) +'x' + str(height) + \"_confusion_matrix_\" + str(model_name) + '.txt'\n",
    "    with open(name,'wb') as f:\n",
    "        for line in mat:\n",
    "            np.savetxt(f, line, fmt='%.2f')\n",
    "    return name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-dd2a0c223afd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mclass_id_to_coco_label_map\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m    \u001B[1;31m# print(name, \":  \",get_F1_score(name))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_all_detections\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcoco_readable_to_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"detections for \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"   \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_all_detections\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcoco_readable_to_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-c0ce0810b50f>\u001B[0m in \u001B[0;36mget_all_detections\u001B[1;34m(class_name)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_all_detections\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcoco_readable_to_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_TP\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcoco_readable_to_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcoco_readable_to_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "confusion_matrix_names = []\n",
    "\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\") # WORKS FAAST\n",
    "confusion_matrix = [[0]*91 for i in range(90)]\n",
    "test_all_dataset('ssd+mobilenet_v2')\n",
    "name = save_confusion_matrix('ssd+mobilenet_v2', width=None, height=None)\n",
    "confusion_matrix_names.append(name)\n",
    "\n",
    "# test_all_dataset(1024,720)\n",
    "# save_confusion_matrix('ssd+mobilenet_v2', width=None, height=None)\n",
    "# test_all_dataset()\n",
    "# save_confusion_matrix('ssd+mobilenet_v2', width=None, height=None)\n",
    "# test_all_dataset()\n",
    "# save_confusion_matrix('ssd+mobilenet_v2', width=None, height=None)\n",
    "\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\") # WORKS FAAST\n",
    "# test_all_dataset()\n",
    "# save_confusion_matrix(model_name, width=None, height=None)\n",
    "\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\") # WORKS FAAST\n",
    "# test_all_dataset()\n",
    "# save_confusion_matrix(model_name, width=None, height=None)\n",
    "#\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\") # WORKS FAAST\n",
    "# test_all_dataset()\n",
    "# save_confusion_matrix(model_name, width=None, height=None)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# mat_from_file = np.loadtxt(\"outfile.txt\", dtype='float', delimiter=' ')\n",
    "# asdf = np.array(mat_from_file)\n",
    "# confusion_matrix = []\n",
    "# with open('outfile.txt', 'r') as f:\n",
    "#     l = [[int(float(num)) for num in line.split(' ')] for line in f]\n",
    "#     confusion_matrix.append(l)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1886,   52,   27, ...,    0,    0, 1009],\n       [  55,  134,    1, ...,    0,    0,   54],\n       [  63,    1,  487, ...,    0,    0,  254],\n       ...,\n       [   8,    0,    0, ...,    0,    0,   13],\n       [   4,    0,    0, ...,    0,   24,  129],\n       [   0,    0,    0, ...,    0,    0,    0]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dupa = np.array(confusion_matrix)\n",
    "# dupa.sum(axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupa\n"
     ]
    }
   ],
   "source": [
    "print(\"dupa\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def open_matrix(filename='outfile_kuba.txt'):\n",
    "    with open(filename, 'r') as f:\n",
    "        l = [[int(float(num)) for num in line.split(' ')] for line in f]\n",
    "    return l\n",
    "\n",
    "confusion_matrix = open_matrix()\n",
    "confusion_matrix = confusion_matrix[:-1]\n",
    "tmp = draw_graphs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}